{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sangjinsu/personalized-recommendation-system/blob/main/MF_%EA%B8%B0%EB%B0%98_%EC%B6%94%EC%B2%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19SyCN7PSCpF"
   },
   "source": [
    "## 메모리 기반 알고리즘\n",
    "\n",
    "- 메모리에 있는 데이터를 계산해서 추천하는 방식\n",
    "- 개별 사용자 데이터 집중\n",
    "- 원래 데이터에 충실하게 사용\n",
    "- 대규모 데이터에 느리게 반응\n",
    "\n",
    "## 모델 기반 알고리즘\n",
    "\n",
    "- 데이터로부터 미리 모델을 구성 후 필요 시 추천하는 방식\n",
    "- 전체 사용자 패턴 집중\n",
    "- 대규모 데이터에 빠르게 반응\n",
    "- 모델 생성 과정 오래 걸림 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27u-TECSTH20"
   },
   "source": [
    "## Matrix Factorization 방식의 원리 \n",
    "\n",
    "### SGD Stochastic Gradient Decent 를 사용한  MF 알고리즘\n",
    "\n",
    "1. 잠재 요인  K 선택\n",
    "2. P, Q 행렬 초기화\n",
    "3. 예측 평점 R_hat 계산\n",
    "4. 실제 R 과 R_hat 간 오차 계산 및 P, Q 수정\n",
    "5. 기존 오차 도달 확인 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Otoh8Zs1EJwu"
   },
   "source": [
    "### SGD 를 사용한 MF 기본 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "SE0SmhNuHjUY",
    "outputId": "2536414d-0136-4fbb-da4e-60bffc28dc07"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating\n",
       "0          196       242       3\n",
       "1          186       302       3\n",
       "2           22       377       1\n",
       "3          244        51       2\n",
       "4          166       346       1\n",
       "...        ...       ...     ...\n",
       "99995      880       476       3\n",
       "99996      716       204       5\n",
       "99997      276      1090       1\n",
       "99998       13       225       2\n",
       "99999       12       203       3\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "base_src = ''\n",
    "u_data_src = os.path.join(base_src, 'u.data')\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv(u_data_src, sep='\\t',\n",
    "                      names=r_cols, encoding='latin-1')\n",
    "\n",
    "# timestamp 제거 \n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)\n",
    "\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EPSQp0EhE49u",
    "outputId": "b93fdd61-cb27-45fd-c918-55cf5d78b86a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 10 ; train RMSE = 0.9585\n",
      "Iteration : 20 ; train RMSE = 0.9374\n",
      "Iteration : 30 ; train RMSE = 0.9281\n",
      "Iteration : 40 ; train RMSE = 0.9226\n",
      "Iteration : 50 ; train RMSE = 0.9185\n",
      "Iteration : 60 ; train RMSE = 0.9147\n",
      "Iteration : 70 ; train RMSE = 0.9102\n",
      "Iteration : 80 ; train RMSE = 0.9042\n",
      "Iteration : 90 ; train RMSE = 0.8957\n",
      "Iteration : 100 ; train RMSE = 0.8842\n"
     ]
    }
   ],
   "source": [
    "class MF():\n",
    "  def __init__(self, ratings, hyper_params):\n",
    "    self.R = np.array(ratings)\n",
    "    self.num_users, self.num_items = np.shape(self.R)\n",
    "    self.K = hyper_params['K']\n",
    "    self.alpha = hyper_params['alpha']\n",
    "    self.beta = hyper_params['beta']\n",
    "    self.iterations = hyper_params['iterations']\n",
    "    self.verbose = hyper_params['verbose']\n",
    "\n",
    "  def rmse(self):\n",
    "    xs, ys = self.R.nonzero()\n",
    "    self.predictions = []\n",
    "    self.errors = [] \n",
    "\n",
    "    for x, y in zip(xs, ys):\n",
    "      prediction = self.get_prediction(x, y)\n",
    "      self.predictions.append(prediction)\n",
    "      self.errors.append(self.R[x,y] - prediction)\n",
    "    self.prediction = np.array(self.predictions)\n",
    "    self.errors = np.array(self.errors)\n",
    "\n",
    "    return np.sqrt(np.mean(self.errors ** 2))\n",
    "\n",
    "  def train(self):\n",
    "    self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "    self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "    self.b_u = np.zeros(self.num_users)\n",
    "    self.b_d = np.zeros(self.num_items)\n",
    "    self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "    rows, columns = self.R.nonzero()\n",
    "    self.samples = [(i,j,self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "    training_process = []\n",
    "    for i in range(self.iterations):\n",
    "      np.random.shuffle(self.samples)\n",
    "      self.sgd()\n",
    "      rmse = self.rmse()\n",
    "      training_process.append((i+1, rmse))\n",
    "      if self.verbose:\n",
    "        if (i+1) % 10 == 0:\n",
    "          print('Iteration : %d ; train RMSE = %.4f' % (i+1, rmse))\n",
    "    return training_process\n",
    "\n",
    "  def get_prediction(self, i, j):\n",
    "    prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i,:].dot(self.Q[j,].T)\n",
    "    return prediction\n",
    "\n",
    "  def sgd(self):\n",
    "    for i, j, r in self.samples:\n",
    "      prediction = self.get_prediction(i, j)\n",
    "      e = (r-prediction)\n",
    "      self.b_u[i] += self.alpha * (e - (self.beta * self.b_u[i]))\n",
    "      self.b_d[j] += self.alpha * (e - (self.beta * self.b_d[j]))\n",
    "\n",
    "      self.P[i, :] += self.alpha * ((e * self.Q[j,:]) - (self.beta * self.P[i, :]))\n",
    "      self.Q[j, :] += self.alpha * ((e * self.P[i,:]) - (self.beta * self.Q[j, :]))\n",
    "\n",
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "\n",
    "hyper_params = {\n",
    "    'K' : 30,\n",
    "    'alpha' : 0.001,\n",
    "    'beta' : 0.02,\n",
    "    'iterations' : 100,\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "\n",
    "mf = MF(R_temp, hyper_params)\n",
    "\n",
    "train_process = mf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EiP_Mjh4Vs-4",
    "outputId": "b44ca043-4706-459a-812b-d256a22a350c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 10 ; train RMSE = 0.9666 ; TEST RMSE = 0.9808\n",
      "Iteration : 20 ; train RMSE = 0.9413 ; TEST RMSE = 0.9623\n",
      "Iteration : 30 ; train RMSE = 0.9298 ; TEST RMSE = 0.9552\n",
      "Iteration : 40 ; train RMSE = 0.9229 ; TEST RMSE = 0.9515\n",
      "Iteration : 50 ; train RMSE = 0.9181 ; TEST RMSE = 0.9493\n",
      "Iteration : 60 ; train RMSE = 0.9141 ; TEST RMSE = 0.9478\n",
      "Iteration : 70 ; train RMSE = 0.9104 ; TEST RMSE = 0.9466\n",
      "Iteration : 80 ; train RMSE = 0.9063 ; TEST RMSE = 0.9455\n",
      "Iteration : 90 ; train RMSE = 0.9013 ; TEST RMSE = 0.9442\n",
      "Iteration : 100 ; train RMSE = 0.8948 ; TEST RMSE = 0.9425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 1.0785528204623365, 1.0811946572557523),\n",
       " (2, 1.048112586724565, 1.0524044673865895),\n",
       " (3, 1.0270261325409036, 1.032883770075201),\n",
       " (4, 1.0115310878453625, 1.0188485154501268),\n",
       " (5, 0.9997069875375423, 1.0083705586952645),\n",
       " (6, 0.9903671729572684, 1.0002847525781493),\n",
       " (7, 0.9827860016417718, 0.9938762795421552),\n",
       " (8, 0.9765117410151863, 0.9886651776121215),\n",
       " (9, 0.9712028279939494, 0.9843604038495879),\n",
       " (10, 0.9666484071915243, 0.9807542145011063),\n",
       " (11, 0.9626920611346451, 0.9776612041309483),\n",
       " (12, 0.9592127570476289, 0.9750143989059324),\n",
       " (13, 0.956120144527099, 0.9727156169584853),\n",
       " (14, 0.953353399204173, 0.9706798356043633),\n",
       " (15, 0.950858047157538, 0.9688829290262317),\n",
       " (16, 0.948595179401085, 0.9672815342832055),\n",
       " (17, 0.9465274835739478, 0.9658501227754327),\n",
       " (18, 0.9446279272252764, 0.9645558061403112),\n",
       " (19, 0.942878477450391, 0.9633887168375573),\n",
       " (20, 0.9412603085423641, 0.9623130411105273),\n",
       " (21, 0.9397586782830825, 0.9613238960443456),\n",
       " (22, 0.9383573106829176, 0.9604132408051662),\n",
       " (23, 0.9370489046722846, 0.9595761482346121),\n",
       " (24, 0.9358237337806106, 0.9588125364996202),\n",
       " (25, 0.9346724779635073, 0.9581150113113638),\n",
       " (26, 0.9335859442945561, 0.957444664798607),\n",
       " (27, 0.9325622642724963, 0.9568246148727876),\n",
       " (28, 0.9315928696945291, 0.9562422762641893),\n",
       " (29, 0.9306732559897294, 0.9556981824502361),\n",
       " (30, 0.9298013927117635, 0.9552000498389432),\n",
       " (31, 0.9289701732968111, 0.9547282949533331),\n",
       " (32, 0.9281787520121271, 0.9542946725317707),\n",
       " (33, 0.9274215297800498, 0.9538791034829559),\n",
       " (34, 0.9266994066580762, 0.9534885854018595),\n",
       " (35, 0.9260091035474811, 0.9531006670614868),\n",
       " (36, 0.9253451634337313, 0.9527354525093185),\n",
       " (37, 0.9247085921623397, 0.95240369130091),\n",
       " (38, 0.9240951160475559, 0.9521034999517112),\n",
       " (39, 0.9235030120535866, 0.9518074016450749),\n",
       " (40, 0.9229329930057051, 0.9515200106943937),\n",
       " (41, 0.9223820273807575, 0.9512478153039836),\n",
       " (42, 0.9218487173277925, 0.9510037725602526),\n",
       " (43, 0.9213310529764563, 0.9507511469279406),\n",
       " (44, 0.9208299718549317, 0.9505077662057293),\n",
       " (45, 0.9203407027392373, 0.950272897918658),\n",
       " (46, 0.9198663757278157, 0.9500646423190832),\n",
       " (47, 0.9194046479871641, 0.9498575501835538),\n",
       " (48, 0.91895428770623, 0.9496604868496165),\n",
       " (49, 0.9185141452212253, 0.9494919898402012),\n",
       " (50, 0.9180823956359273, 0.9493085279533326),\n",
       " (51, 0.917660012369882, 0.949128887085648),\n",
       " (52, 0.9172431923062127, 0.9489631383871765),\n",
       " (53, 0.9168349624030556, 0.9488075651178521),\n",
       " (54, 0.9164335922385323, 0.9486519376480717),\n",
       " (55, 0.9160374760182363, 0.9484957512858475),\n",
       " (56, 0.9156445372353976, 0.9483551997932677),\n",
       " (57, 0.9152578983677929, 0.9482115139719003),\n",
       " (58, 0.9148761392107184, 0.9480570474284994),\n",
       " (59, 0.9144957097294251, 0.9479134908100981),\n",
       " (60, 0.9141181186427771, 0.9477780945831176),\n",
       " (61, 0.9137442774580866, 0.9476461648376894),\n",
       " (62, 0.9133672238328763, 0.9475318816156162),\n",
       " (63, 0.9129957453193688, 0.947420790962251),\n",
       " (64, 0.9126224982239932, 0.9473010550462412),\n",
       " (65, 0.9122487686686381, 0.9471749148189663),\n",
       " (66, 0.9118734035373179, 0.9470674788294808),\n",
       " (67, 0.9114979546288898, 0.9469396068146629),\n",
       " (68, 0.9111240426336324, 0.9468354630772072),\n",
       " (69, 0.9107441384429059, 0.9467394454954531),\n",
       " (70, 0.9103627595292101, 0.9466217911572642),\n",
       " (71, 0.9099762592667656, 0.9465170256078855),\n",
       " (72, 0.9095898075697473, 0.946398108695458),\n",
       " (73, 0.9091943141757929, 0.9462949263770323),\n",
       " (74, 0.9087941601451, 0.9461805041412839),\n",
       " (75, 0.9083921224576267, 0.9460529834379321),\n",
       " (76, 0.9079814611161947, 0.9459659687049319),\n",
       " (77, 0.9075632761564052, 0.9458492320475789),\n",
       " (78, 0.9071408404606839, 0.9457329867424986),\n",
       " (79, 0.9067084802527431, 0.9456133923002498),\n",
       " (80, 0.9062707866599254, 0.9454961489057472),\n",
       " (81, 0.9058210418600028, 0.9453928715076867),\n",
       " (82, 0.9053644147942517, 0.9452651292437821),\n",
       " (83, 0.904895819527491, 0.9451338787429722),\n",
       " (84, 0.9044171123645992, 0.9450114785205921),\n",
       " (85, 0.9039293060045089, 0.9448714958787833),\n",
       " (86, 0.9034270016587846, 0.9447336317932817),\n",
       " (87, 0.9029155694745464, 0.9445942845317432),\n",
       " (88, 0.9023868826259377, 0.944462706649243),\n",
       " (89, 0.9018454066716454, 0.9443276976807891),\n",
       " (90, 0.9012895559083361, 0.944181187715594),\n",
       " (91, 0.9007201624343758, 0.9440415691861302),\n",
       " (92, 0.9001354232202521, 0.9438854722986193),\n",
       " (93, 0.8995347744041546, 0.943719941237664),\n",
       " (94, 0.8989161092129136, 0.9435492596174386),\n",
       " (95, 0.8982798614633155, 0.9433817162802954),\n",
       " (96, 0.8976258088078247, 0.9431982546678737),\n",
       " (97, 0.8969550325232473, 0.9430259790941243),\n",
       " (98, 0.8962643883394329, 0.9428541029257431),\n",
       " (99, 0.895552537371631, 0.942669952009482),\n",
       " (100, 0.8948200576038552, 0.9424574488069627)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "base_src = ''\n",
    "u_data_src = os.path.join(base_src, 'u.data')\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv(u_data_src, sep='\\t',\n",
    "                      names=r_cols, encoding='latin-1')\n",
    "\n",
    "# timestamp 제거 \n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)\n",
    "\n",
    "# train / test set 분리\n",
    "from sklearn.utils import shuffle \n",
    "TRAIN_SIZE = 0.75\n",
    "# (사용자 - 영화 - 평점)\n",
    "ratings = shuffle(ratings, random_state= 2021)\n",
    "cutoff = int(TRAIN_SIZE * len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]\n",
    "\n",
    "class NEW_MF():\n",
    "  def __init__(self, ratings, hyper_params):\n",
    "    self.R = np.array(ratings)\n",
    "    # 사용자 수 (num_users) 와 아이템 수(num_items)를 받아온다\n",
    "    self.num_users, self.num_items = np.shape(self.R)\n",
    "    # 아래는 MF weight 조절을 위한 하이퍼파라미터이다\n",
    "    # K : 잠재요인(latent factor)의 수\n",
    "    self.K = hyper_params['K']\n",
    "    # alpha 학습률\n",
    "    self.alpha = hyper_params['alpha']\n",
    "    # beta  정규화 계수\n",
    "    self.beta = hyper_params['beta']\n",
    "    # iterations SGD 계산을 할 때의 반복 횟수\n",
    "    self.iterations = hyper_params['iterations']\n",
    "    # verbose SGD 학습 과정을 중간중간에 출력할 것인지에 대한 여부\n",
    "    self.verbose = hyper_params['verbose']\n",
    "\n",
    "    item_id_index = []\n",
    "    index_item_id = []\n",
    "    for i, one_id in enumerate(ratings):\n",
    "      item_id_index.append([one_id, i])\n",
    "      index_item_id.append([i, one_id])\n",
    "    self.item_id_index = dict(item_id_index)\n",
    "    self.index_item_id = dict(index_item_id)\n",
    "\n",
    "    user_id_index = []\n",
    "    index_user_id = []\n",
    "    for i, one_id in enumerate(ratings.T):\n",
    "      user_id_index.append([one_id, i])\n",
    "      index_user_id.append([i, one_id])\n",
    "    self.user_id_index = dict(user_id_index)\n",
    "    self.index_user_id = dict(index_user_id)    \n",
    "\n",
    "\n",
    "  def rmse(self):\n",
    "    # self.R 에서 평점이 있는 요소의 인덱스를 가져온다 \n",
    "    xs, ys = self.R.nonzero()\n",
    "    # prediction 과 error를 담을 리스트 변수 초기화 \n",
    "    self.predictions = []\n",
    "    self.errors = [] \n",
    "    # 평점이 있는 요소 (사용자 x, 아이템 y) 각각에 대해서 아래의 코드를 실행한다\n",
    "    for x, y in zip(xs, ys):\n",
    "      # 사용자 x, 아이템 y 에 대해 평점 예측치를 get_prediction() 함수를 사용해서 계산한다.\n",
    "      prediction = self.get_prediction(x, y)\n",
    "      # 예측값을 예측값 리스트에 추가한다 \n",
    "      self.predictions.append(prediction)\n",
    "      # 실제값 과 예측값의 차이를 계산해서 오차값 리스트에 추가한다\n",
    "      self.errors.append(self.R[x,y] - prediction)\n",
    "    # 예측값 리스트와 오차값 리스트를 numpy array 형태로 변환한다.\n",
    "    self.prediction = np.array(self.predictions)\n",
    "    self.errors = np.array(self.errors)\n",
    "    # error를 활용해서 RMSE 도출 \n",
    "    return np.sqrt(np.mean(self.errors ** 2))\n",
    "\n",
    "  def sgd(self):\n",
    "    for i, j, r in self.samples:\n",
    "      # 사용자 i, 아이템 j 에 대한 평저 예측치 계산\n",
    "      prediction = self.get_prediction(i, j)\n",
    "      # 실제 평점과 비교한 오차 계산\n",
    "      e = (r-prediction)\n",
    "\n",
    "      # 사용자 평가 경향 계산 및 업데이트\n",
    "      self.b_u[i] += self.alpha * (e - (self.beta * self.b_u[i]))\n",
    "      # 아이템 평가 경향 계산 및 업데이트\n",
    "      self.b_d[j] += self.alpha * (e - (self.beta * self.b_d[j]))\n",
    "\n",
    "      # P 행렬 계산 및 업데이트\n",
    "      self.P[i, :] += self.alpha * ((e * self.Q[j,:]) - (self.beta * self.P[i, :]))\n",
    "      # Q 행렬 계산 및 업데이트\n",
    "      self.Q[j, :] += self.alpha * ((e * self.P[i,:]) - (self.beta * self.Q[j, :]))\n",
    "  \n",
    "  def get_prediction(self, i, j):\n",
    "    # 사용자 i, 아이템 j에 대한 평점 예측치를 앞에서 배웠던 식을 이용해서 구한다 \n",
    "    prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i,:].dot(self.Q[j,].T)\n",
    "    return prediction\n",
    " \n",
    "  #  Test set 선정\n",
    "  def set_test(self, ratings_test):\n",
    "    test_set = []\n",
    "    for i in range(len(ratings_test)):\n",
    "      x = self.user_id_index[ratings_test.iloc[i, 0]]\n",
    "      y = self.item_id_index[ratings_test.iloc[i, 1]]\n",
    "      z = ratings_test.iloc[i, 2]\n",
    "      test_set.append([x, y, z])\n",
    "      self.R[x, y] = 0\n",
    "    self.test_set = test_set \n",
    "    return test_set\n",
    "\n",
    "  # Test set RMSE 계산 \n",
    "  def test_rmse(self):\n",
    "    error = 0\n",
    "    for one_set in self.test_set:\n",
    "      predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "      # e => e^2\n",
    "      error += pow(one_set[2] - predicted, 2)\n",
    "    return np.sqrt(error/len(self.test_set))\n",
    "\n",
    "  def test(self):\n",
    "    self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "    self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "    self.b_u = np.zeros(self.num_users)\n",
    "    self.b_d = np.zeros(self.num_items)\n",
    "    self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "    rows, columns = self.R.nonzero()\n",
    "    self.samples = [(i,j,self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "    training_process = []\n",
    "    for i in range(self.iterations):\n",
    "      np.random.shuffle(self.samples)\n",
    "      self.sgd()\n",
    "      rmse1 = self.rmse()\n",
    "      rmse2 = self.test_rmse()\n",
    "      training_process.append((i+1, rmse1, rmse2))\n",
    "      if self.verbose:\n",
    "        if (i+1) % 10 == 0:\n",
    "          print('Iteration : %d ; train RMSE = %.4f ; TEST RMSE = %.4f' % (i+1, rmse1, rmse2))\n",
    "    return training_process\n",
    "\n",
    "  def get_one_prediction(self, user_id, item_id):\n",
    "    return self.get_prediction(self.user_id_index[user_id],\n",
    "                               self.item_id_index[item_id])\n",
    "    \n",
    "  def full_prediction(self):\n",
    "    return self.b + self.b_u[:,np.newaxis] + self.b_d[np.newaxis,:] + self.P.dot(self.Q.T)\n",
    "\n",
    "\n",
    "R_temp = ratings.pivot(index='user_id',\n",
    "                       columns='movie_id',\n",
    "                       values='rating').fillna(0)\n",
    "\n",
    "hyper_params = {\n",
    "    'K' : 30,\n",
    "    'alpha' : 0.001,\n",
    "    'beta' : 0.02,\n",
    "    'iterations' : 100,\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "\n",
    "mf = NEW_MF(R_temp, hyper_params)\n",
    "train_set = mf.set_test(ratings_test)\n",
    "result = mf.test()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M5gBFhmggot7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.9460257  3.34712027 3.0157985  ... 3.38443895 3.46429479 3.44340934]\n",
      " [3.80141464 3.27389022 2.88584952 ... 3.2488917  3.37956743 3.35109813]\n",
      " [3.41894743 2.86057519 2.48649329 ... 2.85178375 2.97447502 2.95584616]\n",
      " ...\n",
      " [4.15412261 3.61630126 3.23799742 ... 3.58303555 3.7066859  3.68075501]\n",
      " [4.32259529 3.77230274 3.36636627 ... 3.7537767  3.87914574 3.85847726]\n",
      " [3.83766604 3.3516025  2.95924141 ... 3.28037814 3.39620826 3.37024272]]\n"
     ]
    }
   ],
   "source": [
    "print(mf.full_prediction())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K4J_qMZegzfc",
    "outputId": "a35394f4-16d7-4f3a-c335-a60a4a1845f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.347120266603318\n"
     ]
    }
   ],
   "source": [
    "print(mf.get_one_prediction(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYwp-sCBiT06"
   },
   "source": [
    "### MF 최적의 파라미터 찾기  \n",
    "\n",
    "1. 대략적인 최적의 K 위치 찾기\n",
    "2. 대략적 K 주변 탐색으로 최적 K 찾기\n",
    "3. 주어진 K 통해 최적의 iterations 선택 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "id": "3RFUTYwGz7ri",
    "outputId": "9a97575d-235e-4bb4-fbc5-00cc71c8106f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K : 50\n",
      "Iteration : 10 ; train RMSE = 0.9669 ; TEST RMSE = 0.9807\n",
      "Iteration : 20 ; train RMSE = 0.9417 ; TEST RMSE = 0.9622\n",
      "Iteration : 30 ; train RMSE = 0.9305 ; TEST RMSE = 0.9551\n",
      "Iteration : 40 ; train RMSE = 0.9239 ; TEST RMSE = 0.9514\n",
      "Iteration : 50 ; train RMSE = 0.9194 ; TEST RMSE = 0.9492\n",
      "Iteration : 60 ; train RMSE = 0.9158 ; TEST RMSE = 0.9477\n",
      "Iteration : 70 ; train RMSE = 0.9127 ; TEST RMSE = 0.9466\n",
      "Iteration : 80 ; train RMSE = 0.9093 ; TEST RMSE = 0.9456\n",
      "Iteration : 90 ; train RMSE = 0.9053 ; TEST RMSE = 0.9443\n",
      "Iteration : 100 ; train RMSE = 0.9002 ; TEST RMSE = 0.9427\n",
      "K : 60\n",
      "Iteration : 10 ; train RMSE = 0.9669 ; TEST RMSE = 0.9807\n",
      "Iteration : 20 ; train RMSE = 0.9418 ; TEST RMSE = 0.9622\n",
      "Iteration : 30 ; train RMSE = 0.9307 ; TEST RMSE = 0.9551\n",
      "Iteration : 40 ; train RMSE = 0.9242 ; TEST RMSE = 0.9515\n",
      "Iteration : 50 ; train RMSE = 0.9198 ; TEST RMSE = 0.9493\n",
      "Iteration : 60 ; train RMSE = 0.9165 ; TEST RMSE = 0.9479\n",
      "Iteration : 70 ; train RMSE = 0.9136 ; TEST RMSE = 0.9468\n",
      "Iteration : 80 ; train RMSE = 0.9108 ; TEST RMSE = 0.9459\n",
      "Iteration : 90 ; train RMSE = 0.9075 ; TEST RMSE = 0.9450\n",
      "Iteration : 100 ; train RMSE = 0.9033 ; TEST RMSE = 0.9437\n",
      "K : 70\n",
      "Iteration : 10 ; train RMSE = 0.9670 ; TEST RMSE = 0.9807\n",
      "Iteration : 20 ; train RMSE = 0.9419 ; TEST RMSE = 0.9622\n",
      "Iteration : 30 ; train RMSE = 0.9308 ; TEST RMSE = 0.9551\n",
      "Iteration : 40 ; train RMSE = 0.9244 ; TEST RMSE = 0.9515\n",
      "Iteration : 50 ; train RMSE = 0.9201 ; TEST RMSE = 0.9493\n",
      "Iteration : 60 ; train RMSE = 0.9169 ; TEST RMSE = 0.9479\n",
      "Iteration : 70 ; train RMSE = 0.9141 ; TEST RMSE = 0.9469\n",
      "Iteration : 80 ; train RMSE = 0.9115 ; TEST RMSE = 0.9460\n",
      "Iteration : 90 ; train RMSE = 0.9085 ; TEST RMSE = 0.9451\n",
      "Iteration : 100 ; train RMSE = 0.9047 ; TEST RMSE = 0.9439\n",
      "K : 80\n",
      "Iteration : 10 ; train RMSE = 0.9670 ; TEST RMSE = 0.9807\n",
      "Iteration : 20 ; train RMSE = 0.9420 ; TEST RMSE = 0.9622\n",
      "Iteration : 30 ; train RMSE = 0.9309 ; TEST RMSE = 0.9552\n",
      "Iteration : 40 ; train RMSE = 0.9246 ; TEST RMSE = 0.9515\n",
      "Iteration : 50 ; train RMSE = 0.9203 ; TEST RMSE = 0.9494\n",
      "Iteration : 60 ; train RMSE = 0.9172 ; TEST RMSE = 0.9480\n",
      "Iteration : 70 ; train RMSE = 0.9146 ; TEST RMSE = 0.9470\n",
      "Iteration : 80 ; train RMSE = 0.9121 ; TEST RMSE = 0.9462\n",
      "Iteration : 90 ; train RMSE = 0.9095 ; TEST RMSE = 0.9454\n",
      "Iteration : 100 ; train RMSE = 0.9062 ; TEST RMSE = 0.9445\n",
      "K : 90\n",
      "Iteration : 10 ; train RMSE = 0.9670 ; TEST RMSE = 0.9806\n",
      "Iteration : 20 ; train RMSE = 0.9420 ; TEST RMSE = 0.9622\n",
      "Iteration : 30 ; train RMSE = 0.9310 ; TEST RMSE = 0.9551\n",
      "Iteration : 40 ; train RMSE = 0.9246 ; TEST RMSE = 0.9515\n",
      "Iteration : 50 ; train RMSE = 0.9204 ; TEST RMSE = 0.9493\n",
      "Iteration : 60 ; train RMSE = 0.9174 ; TEST RMSE = 0.9480\n",
      "Iteration : 70 ; train RMSE = 0.9148 ; TEST RMSE = 0.9470\n",
      "Iteration : 80 ; train RMSE = 0.9125 ; TEST RMSE = 0.9462\n",
      "Iteration : 90 ; train RMSE = 0.9099 ; TEST RMSE = 0.9454\n",
      "Iteration : 100 ; train RMSE = 0.9068 ; TEST RMSE = 0.9445\n",
      "K : 100\n",
      "Iteration : 10 ; train RMSE = 0.9670 ; TEST RMSE = 0.9807\n",
      "Iteration : 20 ; train RMSE = 0.9421 ; TEST RMSE = 0.9622\n",
      "Iteration : 30 ; train RMSE = 0.9311 ; TEST RMSE = 0.9552\n",
      "Iteration : 40 ; train RMSE = 0.9247 ; TEST RMSE = 0.9515\n",
      "Iteration : 50 ; train RMSE = 0.9206 ; TEST RMSE = 0.9494\n",
      "Iteration : 60 ; train RMSE = 0.9176 ; TEST RMSE = 0.9480\n",
      "Iteration : 70 ; train RMSE = 0.9151 ; TEST RMSE = 0.9470\n",
      "Iteration : 80 ; train RMSE = 0.9129 ; TEST RMSE = 0.9463\n",
      "Iteration : 90 ; train RMSE = 0.9106 ; TEST RMSE = 0.9456\n",
      "Iteration : 100 ; train RMSE = 0.9078 ; TEST RMSE = 0.9448\n",
      "K : 110\n",
      "Iteration : 10 ; train RMSE = 0.9671 ; TEST RMSE = 0.9807\n",
      "Iteration : 20 ; train RMSE = 0.9421 ; TEST RMSE = 0.9622\n",
      "Iteration : 30 ; train RMSE = 0.9311 ; TEST RMSE = 0.9552\n",
      "Iteration : 40 ; train RMSE = 0.9248 ; TEST RMSE = 0.9515\n",
      "Iteration : 50 ; train RMSE = 0.9207 ; TEST RMSE = 0.9494\n",
      "Iteration : 60 ; train RMSE = 0.9177 ; TEST RMSE = 0.9480\n",
      "Iteration : 70 ; train RMSE = 0.9153 ; TEST RMSE = 0.9470\n",
      "Iteration : 80 ; train RMSE = 0.9132 ; TEST RMSE = 0.9463\n",
      "Iteration : 90 ; train RMSE = 0.9109 ; TEST RMSE = 0.9456\n",
      "Iteration : 100 ; train RMSE = 0.9083 ; TEST RMSE = 0.9448\n",
      "K : 120\n",
      "Iteration : 10 ; train RMSE = 0.9671 ; TEST RMSE = 0.9807\n",
      "Iteration : 20 ; train RMSE = 0.9421 ; TEST RMSE = 0.9622\n",
      "Iteration : 30 ; train RMSE = 0.9312 ; TEST RMSE = 0.9551\n",
      "Iteration : 40 ; train RMSE = 0.9249 ; TEST RMSE = 0.9515\n",
      "Iteration : 50 ; train RMSE = 0.9207 ; TEST RMSE = 0.9494\n",
      "Iteration : 60 ; train RMSE = 0.9178 ; TEST RMSE = 0.9480\n",
      "Iteration : 70 ; train RMSE = 0.9154 ; TEST RMSE = 0.9470\n",
      "Iteration : 80 ; train RMSE = 0.9133 ; TEST RMSE = 0.9463\n",
      "Iteration : 90 ; train RMSE = 0.9111 ; TEST RMSE = 0.9456\n",
      "Iteration : 100 ; train RMSE = 0.9085 ; TEST RMSE = 0.9448\n",
      "K : 130\n",
      "Iteration : 10 ; train RMSE = 0.9671 ; TEST RMSE = 0.9807\n",
      "Iteration : 20 ; train RMSE = 0.9422 ; TEST RMSE = 0.9622\n",
      "Iteration : 30 ; train RMSE = 0.9312 ; TEST RMSE = 0.9552\n",
      "Iteration : 40 ; train RMSE = 0.9249 ; TEST RMSE = 0.9515\n",
      "Iteration : 50 ; train RMSE = 0.9208 ; TEST RMSE = 0.9494\n",
      "Iteration : 60 ; train RMSE = 0.9179 ; TEST RMSE = 0.9480\n",
      "Iteration : 70 ; train RMSE = 0.9156 ; TEST RMSE = 0.9471\n",
      "Iteration : 80 ; train RMSE = 0.9135 ; TEST RMSE = 0.9464\n",
      "Iteration : 90 ; train RMSE = 0.9114 ; TEST RMSE = 0.9457\n",
      "Iteration : 100 ; train RMSE = 0.9090 ; TEST RMSE = 0.9450\n",
      "K : 140\n",
      "Iteration : 10 ; train RMSE = 0.9671 ; TEST RMSE = 0.9807\n",
      "Iteration : 20 ; train RMSE = 0.9422 ; TEST RMSE = 0.9622\n",
      "Iteration : 30 ; train RMSE = 0.9312 ; TEST RMSE = 0.9552\n",
      "Iteration : 40 ; train RMSE = 0.9250 ; TEST RMSE = 0.9515\n",
      "Iteration : 50 ; train RMSE = 0.9209 ; TEST RMSE = 0.9494\n",
      "Iteration : 60 ; train RMSE = 0.9180 ; TEST RMSE = 0.9480\n",
      "Iteration : 70 ; train RMSE = 0.9157 ; TEST RMSE = 0.9471\n",
      "Iteration : 80 ; train RMSE = 0.9137 ; TEST RMSE = 0.9463\n",
      "Iteration : 90 ; train RMSE = 0.9117 ; TEST RMSE = 0.9457\n",
      "Iteration : 100 ; train RMSE = 0.9094 ; TEST RMSE = 0.9450\n",
      "K : 150\n",
      "Iteration : 10 ; train RMSE = 0.9671 ; TEST RMSE = 0.9807\n",
      "Iteration : 20 ; train RMSE = 0.9422 ; TEST RMSE = 0.9622\n",
      "Iteration : 30 ; train RMSE = 0.9313 ; TEST RMSE = 0.9552\n",
      "Iteration : 40 ; train RMSE = 0.9250 ; TEST RMSE = 0.9515\n",
      "Iteration : 50 ; train RMSE = 0.9209 ; TEST RMSE = 0.9494\n",
      "Iteration : 60 ; train RMSE = 0.9181 ; TEST RMSE = 0.9480\n",
      "Iteration : 70 ; train RMSE = 0.9158 ; TEST RMSE = 0.9471\n",
      "Iteration : 80 ; train RMSE = 0.9139 ; TEST RMSE = 0.9464\n",
      "Iteration : 90 ; train RMSE = 0.9119 ; TEST RMSE = 0.9458\n",
      "Iteration : 100 ; train RMSE = 0.9098 ; TEST RMSE = 0.9451\n",
      "K : 160\n"
     ]
    }
   ],
   "source": [
    "# 최적의 K 값 찾기 \n",
    "results = []\n",
    "index = []\n",
    "\n",
    "R_temp = ratings.pivot(index='user_id',\n",
    "                       columns='movie_id',\n",
    "                       values='rating').fillna(0)\n",
    "\n",
    "for K in range(50, 261, 10):\n",
    "  print('K : ' + str(K))\n",
    "  hyper_params = {\n",
    "    'K' : K,\n",
    "    'alpha' : 0.001,\n",
    "    'beta' : 0.02,\n",
    "    'iterations' : 100,\n",
    "    'verbose': True\n",
    "  }\n",
    "\n",
    "  mf = NEW_MF(R_temp,\n",
    "              hyper_params)\n",
    "  test_set = mf.set_test(ratings_test)\n",
    "  result = mf.test()\n",
    "  index.append(K)\n",
    "  results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []\n",
    "for i in range(len(result)):\n",
    "    RMSE = []\n",
    "    for result in results[i]:\n",
    "        RMSE.append(result[2])\n",
    "    min = np.min(RMSE)\n",
    "    j = RMSE.index(min)\n",
    "    summary.append([index[i], j+1, RMSE[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MF와 SVD\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNAW2c2ACQ0pGRikM5wYf9p",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1sQqhyUDr5AOB9JxT0UiSITRqoQT0RjW5",
   "name": "MF 기반 추천",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
