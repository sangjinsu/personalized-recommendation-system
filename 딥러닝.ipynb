{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝을 사용한 추천 시스템"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization MF 신경망으로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일에서 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Add, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD, Adamax\n",
    "\n",
    "\n",
    "base_src = ''\n",
    "u_data_src = os.path.join(base_src, 'u.data')\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv(u_data_src, sep='\\t',\n",
    "                      names=r_cols, encoding='latin-1')\n",
    "\n",
    "ratings_train, ratings_test = train_test_split(\n",
    "    ratings,\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=2022\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 200\n",
    "\n",
    "mu = ratings_train.rating.mean()\n",
    "\n",
    "M = ratings.user_id.max() + 1\n",
    "N = ratings.movie_id.max() + 1\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true-y_pred)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = Input(shape=(1,))\n",
    "item = Input(shape=(1,))\n",
    "\n",
    "P_embedding = Embedding(M, K, embeddings_regularizer=l2())(user)\n",
    "Q_embedding = Embedding(N, K, embeddings_regularizer=l2())(item)\n",
    "\n",
    "user_bias = Embedding(M, 1, embeddings_regularizer=l2())(user)\n",
    "item_bias = Embedding(M, 1, embeddings_regularizer=l2())(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 1, 200)       188800      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 1, 200)       336600      ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dot_19 (Dot)                   (None, 1, 1)         0           ['embedding_4[0][0]',            \n",
      "                                                                  'embedding_5[0][0]']            \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 1, 1)         944         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 1, 1)         944         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 1, 1)         0           ['dot_19[0][0]',                 \n",
      "                                                                  'embedding_6[0][0]',            \n",
      "                                                                  'embedding_7[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_17 (Flatten)           (None, 1)            0           ['add_18[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 527,288\n",
      "Trainable params: 527,288\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "R = layers.dot([P_embedding, Q_embedding], axes=(2, 2))\n",
    "R = layers.add([R, user_bias, item_bias])\n",
    "R = Flatten()(R)\n",
    "\n",
    "model = Model(inputs=[user, item], outputs=R)\n",
    "model.compile(\n",
    "    loss=RMSE,\n",
    "    optimizer=SGD(),\n",
    "    metrics=[RMSE]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 2.6320 - RMSE: 1.1106 - val_loss: 2.5364 - val_RMSE: 1.1069\n",
      "Epoch 2/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.4527 - RMSE: 1.1096 - val_loss: 2.3682 - val_RMSE: 1.1059\n",
      "Epoch 3/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.2945 - RMSE: 1.1084 - val_loss: 2.2198 - val_RMSE: 1.1050\n",
      "Epoch 4/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.1548 - RMSE: 1.1074 - val_loss: 2.0889 - val_RMSE: 1.1042\n",
      "Epoch 5/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 2.0316 - RMSE: 1.1066 - val_loss: 1.9734 - val_RMSE: 1.1034\n",
      "Epoch 6/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.9231 - RMSE: 1.1059 - val_loss: 1.8715 - val_RMSE: 1.1027\n",
      "Epoch 7/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.8273 - RMSE: 1.1052 - val_loss: 1.7816 - val_RMSE: 1.1021\n",
      "Epoch 8/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.7426 - RMSE: 1.1041 - val_loss: 1.7023 - val_RMSE: 1.1016\n",
      "Epoch 9/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.6681 - RMSE: 1.1037 - val_loss: 1.6324 - val_RMSE: 1.1010\n",
      "Epoch 10/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6024 - RMSE: 1.1034 - val_loss: 1.5707 - val_RMSE: 1.1006\n",
      "Epoch 11/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.5442 - RMSE: 1.1027 - val_loss: 1.5162 - val_RMSE: 1.1001\n",
      "Epoch 12/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.4930 - RMSE: 1.1022 - val_loss: 1.4682 - val_RMSE: 1.0997\n",
      "Epoch 13/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4478 - RMSE: 1.1019 - val_loss: 1.4259 - val_RMSE: 1.0994\n",
      "Epoch 14/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4081 - RMSE: 1.1018 - val_loss: 1.3885 - val_RMSE: 1.0991\n",
      "Epoch 15/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.3729 - RMSE: 1.1013 - val_loss: 1.3555 - val_RMSE: 1.0987\n",
      "Epoch 16/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3418 - RMSE: 1.1008 - val_loss: 1.3264 - val_RMSE: 1.0985\n",
      "Epoch 17/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.3145 - RMSE: 1.1007 - val_loss: 1.3008 - val_RMSE: 1.0982\n",
      "Epoch 18/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2902 - RMSE: 1.1003 - val_loss: 1.2781 - val_RMSE: 1.0980\n",
      "Epoch 19/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2689 - RMSE: 1.0999 - val_loss: 1.2582 - val_RMSE: 1.0978\n",
      "Epoch 20/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2500 - RMSE: 1.0995 - val_loss: 1.2406 - val_RMSE: 1.0976\n",
      "Epoch 21/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2337 - RMSE: 1.0996 - val_loss: 1.2250 - val_RMSE: 1.0974\n",
      "Epoch 22/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2189 - RMSE: 1.0993 - val_loss: 1.2113 - val_RMSE: 1.0972\n",
      "Epoch 23/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2061 - RMSE: 1.0992 - val_loss: 1.1992 - val_RMSE: 1.0971\n",
      "Epoch 24/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1946 - RMSE: 1.0990 - val_loss: 1.1885 - val_RMSE: 1.0969\n",
      "Epoch 25/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1846 - RMSE: 1.0990 - val_loss: 1.1791 - val_RMSE: 1.0968\n",
      "Epoch 26/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1758 - RMSE: 1.0988 - val_loss: 1.1708 - val_RMSE: 1.0967\n",
      "Epoch 27/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1677 - RMSE: 1.0984 - val_loss: 1.1635 - val_RMSE: 1.0966\n",
      "Epoch 28/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1610 - RMSE: 1.0985 - val_loss: 1.1570 - val_RMSE: 1.0965\n",
      "Epoch 29/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1550 - RMSE: 1.0986 - val_loss: 1.1513 - val_RMSE: 1.0964\n",
      "Epoch 30/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1496 - RMSE: 1.0984 - val_loss: 1.1463 - val_RMSE: 1.0963\n",
      "Epoch 31/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1447 - RMSE: 1.0979 - val_loss: 1.1418 - val_RMSE: 1.0962\n",
      "Epoch 32/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1408 - RMSE: 1.0984 - val_loss: 1.1379 - val_RMSE: 1.0961\n",
      "Epoch 33/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1371 - RMSE: 1.0980 - val_loss: 1.1345 - val_RMSE: 1.0960\n",
      "Epoch 34/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1336 - RMSE: 1.0978 - val_loss: 1.1314 - val_RMSE: 1.0960\n",
      "Epoch 35/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1310 - RMSE: 1.0980 - val_loss: 1.1287 - val_RMSE: 1.0959\n",
      "Epoch 36/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1283 - RMSE: 1.0977 - val_loss: 1.1264 - val_RMSE: 1.0959\n",
      "Epoch 37/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1259 - RMSE: 1.0977 - val_loss: 1.1243 - val_RMSE: 1.0958\n",
      "Epoch 38/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1241 - RMSE: 1.0978 - val_loss: 1.1224 - val_RMSE: 1.0958\n",
      "Epoch 39/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1225 - RMSE: 1.0977 - val_loss: 1.1208 - val_RMSE: 1.0957\n",
      "Epoch 40/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1210 - RMSE: 1.0977 - val_loss: 1.1194 - val_RMSE: 1.0957\n",
      "Epoch 41/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1194 - RMSE: 1.0975 - val_loss: 1.1181 - val_RMSE: 1.0956\n",
      "Epoch 42/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1183 - RMSE: 1.0975 - val_loss: 1.1170 - val_RMSE: 1.0956\n",
      "Epoch 43/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1172 - RMSE: 1.0974 - val_loss: 1.1160 - val_RMSE: 1.0956\n",
      "Epoch 44/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1163 - RMSE: 1.0975 - val_loss: 1.1151 - val_RMSE: 1.0956\n",
      "Epoch 45/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1155 - RMSE: 1.0974 - val_loss: 1.1144 - val_RMSE: 1.0955\n",
      "Epoch 46/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1148 - RMSE: 1.0975 - val_loss: 1.1137 - val_RMSE: 1.0955\n",
      "Epoch 47/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1141 - RMSE: 1.0974 - val_loss: 1.1131 - val_RMSE: 1.0955\n",
      "Epoch 48/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1137 - RMSE: 1.0975 - val_loss: 1.1126 - val_RMSE: 1.0955\n",
      "Epoch 49/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1130 - RMSE: 1.0973 - val_loss: 1.1121 - val_RMSE: 1.0954\n",
      "Epoch 50/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1125 - RMSE: 1.0971 - val_loss: 1.1117 - val_RMSE: 1.0954\n",
      "Epoch 51/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1122 - RMSE: 1.0972 - val_loss: 1.1113 - val_RMSE: 1.0954\n",
      "Epoch 52/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1118 - RMSE: 1.0973 - val_loss: 1.1110 - val_RMSE: 1.0954\n",
      "Epoch 53/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1116 - RMSE: 1.0973 - val_loss: 1.1107 - val_RMSE: 1.0954\n",
      "Epoch 54/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1114 - RMSE: 1.0974 - val_loss: 1.1105 - val_RMSE: 1.0954\n",
      "Epoch 55/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1111 - RMSE: 1.0972 - val_loss: 1.1103 - val_RMSE: 1.0953\n",
      "Epoch 56/60\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1109 - RMSE: 1.0972 - val_loss: 1.1101 - val_RMSE: 1.0953\n",
      "Epoch 57/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1106 - RMSE: 1.0972 - val_loss: 1.1099 - val_RMSE: 1.0953\n",
      "Epoch 58/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1104 - RMSE: 1.0972 - val_loss: 1.1097 - val_RMSE: 1.0953\n",
      "Epoch 59/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1104 - RMSE: 1.0973 - val_loss: 1.1096 - val_RMSE: 1.0953\n",
      "Epoch 60/60\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1103 - RMSE: 1.0973 - val_loss: 1.1095 - val_RMSE: 1.0953\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(\n",
    "    x = [ratings_train.user_id.values,\n",
    "         ratings_train.movie_id.values],\n",
    "    y = ratings_train.rating.values - mu,\n",
    "    epochs = 60,\n",
    "    batch_size = 256,\n",
    "    validation_data = (\n",
    "        [ratings_test.user_id.values,\n",
    "            ratings_test.movie_id.values],\n",
    "        ratings_test.rating.values - mu\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5148dbd1d0990a1c29e36173df2e2382953f242373eaf320dae2341ee5cbc7d2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
